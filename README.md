
# ğŸš€ EchoMind â€“ Offline AI Assistant & Video Intelligence System

EchoMind is a **fully offline, production-ready AI system** designed for **AI hackathons, research, and real-world deployments**.  
The project combines **video analysis, speech processing, computer vision, and an offline chatbot with voice assistant capabilities** â€” all running **without cloud APIs**.

---

## âœ¨ Key Features

### ğŸ¥ Echo-Vision (Video Analysis Mode)
- Upload **video files** or use **offline video sources**
- Extract audio from video
- Speech-to-Text (STT) processing
- Sentiment & contextual analysis
- AI-generated summaries and insights
- Designed for explainable AI outputs

---

### ğŸ¤– Echo-Bot (Offline Chatbot Mode)
- Fully **offline ChatGPT-style chatbot**
- Powered by **Ollama (LLaMA 3.1)** running locally
- Persistent **chat memory per session**
- Multiple chatbot moods:
  - Default
  - Friendly
  - Tutor
  - Analyst

---

### ğŸ™ï¸ Voice Assistant (Chatbot Extension)
- Record voice directly from the browser
- Offline **Speech-to-Text** using Whisper (whisper.cpp)
- AI response generated from transcribed text
- Offline **Text-to-Speech** using Piper
- Returns both:
  - Text response
  - Audio reply

---

### ğŸ§  Computer Vision Capabilities
Using **MediaPipe**, EchoMind supports:
- Face landmark detection
- Hand tracking
- Pose estimation
- Real-time vision processing

---

## ğŸ› ï¸ Technology Stack

**Backend**
- Python
- FastAPI
- Uvicorn
- Jinja2

**AI / ML**
- Ollama (LLaMA 3.1 â€“ offline LLM)
- Whisper.cpp (offline STT)
- Piper (offline TTS)
- MediaPipe (pose, face, hand tracking)
- OpenCV

**Frontend**
- HTML / CSS / JavaScript
- Responsive, modern UI
- Voice recording support

---

## ğŸ“‚ Project Structure


EchoMind/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ routes/        # API & web routes
â”‚   â”œâ”€â”€ services/      # STT, TTS, chatbot, vision logic
â”‚   â”œâ”€â”€ storage/       # Chat memory, audio, results
â”‚   â””â”€â”€ main.py
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ templates/     # HTML templates
â”‚   â””â”€â”€ static/        # CSS, JS, images
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ run.sh
â””â”€â”€ README.md





## ğŸ”’ Offline-First Design

- âŒ No cloud APIs
- âŒ No internet dependency at runtime
- âœ… All models run locally
- âœ… Ideal for privacy-sensitive use cases

---

## ğŸ¯ Use Cases
- AI Hackathons
- Offline AI demos
- Research & experimentation
- Smart assistants
- Human-computer interaction projects
- Computer vision & speech AI systems

---

## âš ï¸ Notes
- Large models and datasets are **not included** in the repository
- Configure local model paths via environment variables
- Designed for **MacOS & Windows** environments

---

## ğŸ‘¨â€ğŸ’» Team EchoMind
Developed with passion by **Team EchoMind**  
Focused on building **practical, offline, and explainable AI systems**.

---

â­ If you find this project useful, feel free to star the repository!
```

